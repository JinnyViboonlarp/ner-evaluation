folder containing gold-standard files: goldfiles-example/
folder containing model prediction files: testfiles-example/
number of pairs of matching annotation files to be evaluated: 2
=======================================================================================

Pair 1
gold-standard file: cpb-this-is-example1-transcript.ann
model prediction file: cpb-this-is-example1.json

Strict Evaluation Result
every token in an entity must have the matching tagging with the gold standard to count as the same entity
              precision    recall  f1-score   support

organization       1.00      1.00      1.00         2
      person       1.00      1.00      1.00         1

   micro avg       1.00      1.00      1.00         3
   macro avg       1.00      1.00      1.00         3
weighted avg       1.00      1.00      1.00         3

Token-based Evaluation Result
the evaluation is done on the token level, and the difference between B- and I- is disregarded
              precision    recall  f1-score   support

organization       1.00      1.00      1.00         2
      person       1.00      1.00      1.00         2

   micro avg       1.00      1.00      1.00         4
   macro avg       1.00      1.00      1.00         4
weighted avg       1.00      1.00      1.00         4

=======================================================================================

Pair 2
gold-standard file: cpb-this-is-example2-transcript.ann
model prediction file: cpb-this-is-example2.json

Strict Evaluation Result
every token in an entity must have the matching tagging with the gold standard to count as the same entity
              precision    recall  f1-score   support

organization       1.00      0.50      0.67         4
      person       1.00      0.50      0.67         2

   micro avg       1.00      0.50      0.67         6
   macro avg       1.00      0.50      0.67         6
weighted avg       1.00      0.50      0.67         6

Token-based Evaluation Result
the evaluation is done on the token level, and the difference between B- and I- is disregarded
              precision    recall  f1-score   support

organization       1.00      0.50      0.67         4
      person       1.00      0.50      0.67         4

   micro avg       1.00      0.50      0.67         8
   macro avg       1.00      0.50      0.67         8
weighted avg       1.00      0.50      0.67         8

=======================================================================================

Aggregated Result from 2 pairs of (gold standard file, model prediction file)

gold-standard file: cpb-this-is-example2-transcript.ann
model prediction file: cpb-this-is-example2.json

Strict Evaluation Result
every token in an entity must have the matching tagging with the gold standard to count as the same entity
              precision    recall  f1-score   support

organization       1.00      0.67      0.80         6
      person       1.00      0.67      0.80         3

   micro avg       1.00      0.67      0.80         9
   macro avg       1.00      0.67      0.80         9
weighted avg       1.00      0.67      0.80         9

Token-based Evaluation Result
the evaluation is done on the token level, and the difference between B- and I- is disregarded
              precision    recall  f1-score   support

organization       1.00      0.67      0.80         6
      person       1.00      0.67      0.80         6

   micro avg       1.00      0.67      0.80        12
   macro avg       1.00      0.67      0.80        12
weighted avg       1.00      0.67      0.80        12

=======================================================================================

the labels from both files are mapped to the following labels
labels not in any column of the following table will be discarded

original_label	mapped_label
PERSON	person
ORG	organization
FAC	location
GPE	location
LOC	location
EVENT	event
PRODUCT	product
WORK_OF_ART	program/publication_title
program_title	program/publication_title
publication_title	program/publication_title